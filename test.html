<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width" />
    <title>Web Audio API examples: MediaStreamAudioSourceNode</title>
  </head>
  <script src="https://cdn.jsdelivr.net/npm/essentia.js@0.1.1/dist/essentia-wasm.web.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/essentia.js@0.1.1/dist/essentia.js-model.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <!-- Import the webpage's javascript file -->

  <body>
    <h1>Web Audio API examples: MediaStreamAudioSourceNode</h1>
    <br />
    <canvas id="oscilloscope"></canvas>

    <p>Biquad filter frequency response for:</p>
    <ul class="freq-response"></ul>
    <script>
  // init audio context: we will need it to decode our audio file
const audioCtx = new (AudioContext || new webkitAudioContext())();

// model variables
const modelURL = "./msd-musicnn-1/model.json";
let extractor = null;
let musicnn = new EssentiaModel.TensorflowMusiCNN(tf, modelURL, true);

// get audio track URL
const audioURL = "https://freesound.org/data/previews/277/277325_4548252-lq.mp3";

window.onload = () => {
  // load Essentia WASM backend
  EssentiaWASM().then(wasmModule => {
    extractor = new EssentiaModel.EssentiaTFInputExtractor(wasmModule, "musicnn", false);
    // fetch audio and decode, then analyse
    extractor.getAudioBufferFromURL(audioURL, audioCtx).then(analyse);
  });
};

// analyse on click
async function analyse(buffer) {
  const audioData = await extractor.downsampleAudioBuffer(buffer);
  const features = await extractor.computeFrameWise(audioData, 256);
  await musicnn.initialize();
  const predictions = await musicnn.predict(features, true);

  // creates a new div to display the predictions and appends to DOM
  showResults(predictions);
}
    </script>
  </body>
</html>